{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0bdee0-2166-41b3-9d27-7ec6aff5e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/omkarjadhav/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/omkarjadhav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e470d-408a-4207-9064-9fa025fecb86",
   "metadata": {},
   "source": [
    "### Step 1 â€“ Dataset Preparation\n",
    "\n",
    "##### Load the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1ab55f-b598-4300-a692-4981e69e7ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
      "conversation?'\n",
      "\n",
      "So she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy an\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Load Alice in wonderland\n",
    "align_text = gutenberg.raw(\"carroll-alice.txt\")\n",
    "print(align_text[:500])\n",
    "\n",
    "\n",
    "\n",
    "# Dummy text corpus\n",
    "text = \"\"\"once upon a time there was a brave knight\n",
    "he fought dragons and protected the kingdom\n",
    "the people loved the knight for his courage and strength\n",
    "every day he trained with sword and shield\n",
    "his legend spread across the land far and wide\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b40de9-158b-44ea-b6c4-7f59065a3af1",
   "metadata": {},
   "source": [
    "### Step 2: Text Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb63241-e4c5-4bf1-b13f-4d657a39cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:  26384\n",
      "First 50 Tokens:  ['alices', 'adventures', 'in', 'wonderland', 'by', 'lewis', 'carroll', '1865', 'chapter', 'i', 'down', 'the', 'rabbithole', 'alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Lowercase\n",
    "text = align_text.lower()\n",
    "\n",
    "# # Remove unwanted characters (keep letters and basic punctuation)\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Total Tokens: \", len(tokens))\n",
    "print(\"First 50 Tokens: \", tokens[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bb68f-0e4d-41bb-b1f5-24a415620f21",
   "metadata": {},
   "source": [
    "### Step 3: Sequence Creation for Training\n",
    "\n",
    "Now that we have a cleaned list of words `(tokens)`, we'll prepare training sequences.\n",
    "\n",
    "Goal:\n",
    "* We want to create many input sequences where each sequence is a few words long, and the next word is the **label**.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "Input Sequence: [\"alice\", \"was\", \"beginning\", \"to\"]    \n",
    "\n",
    "Label: \"get\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0944171b-b124-46c2-ad0e-c6fb4cd91f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 21:30:52.374597: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda17eba-512e-4b1e-88cd-d6b4ea31285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences size:  26384\n",
      "Sequence:  [298, 527, 11, 826, 74, 1470, 1471, 1472, 299, 9]\n",
      "\n",
      "Vocabulary Size:  2753\n",
      "\n",
      "first 5 input sequences:\n",
      " [[298, 527], [298, 527, 11], [298, 527, 11, 826], [298, 527, 11, 826, 74], [298, 527, 11, 826, 74, 1470]]\n",
      "\n",
      "first 5 input sequences After padding:\n",
      " [[   0    0    0 ...    0  298  527]\n",
      " [   0    0    0 ...  298  527   11]\n",
      " [   0    0    0 ...  527   11  826]\n",
      " [   0    0    0 ...   11  826   74]\n",
      " [   0    0    0 ...  826   74 1470]]\n",
      "\n",
      "Input features type:  <class 'numpy.ndarray'>\n",
      "Label type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer and fit on text\n",
    "\n",
    "\"\"\"Below step builds the vocabulary from the list of tokens (words). \n",
    "   Each unique word gets assigned an integer index. \n",
    "   We're using those integer indexes as sequences values. Ex: \"alices\" word have index 298 which we're using to represent that word.\n",
    "\"\"\"\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokens)      # Learn the vocabulary from the text\n",
    "\n",
    "# Convert words to integers\n",
    "sequences = tokenizer.texts_to_sequences([tokens])[0]\n",
    "print(\"sequences size: \", len(sequences))\n",
    "print(\"Sequence: \", sequences[:10])\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"\\nVocabulary Size: \", vocab_size)\n",
    "\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for i in range(1, len(sequences)):\n",
    "    input_sequences.append(sequences[:i+1])\n",
    "print(\"\\nfirst 5 input sequences:\\n\", input_sequences[:5])\n",
    "\n",
    "# Pad sequences to same length\n",
    "max_seq_len = len(input_sequences[-1])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
    "print(\"\\nfirst 5 input sequences After padding:\\n\", input_sequences[:5])\n",
    "\n",
    "# Split into input (X) and label (y)\n",
    "input_sequences = np.array(input_sequences)\n",
    "\"\"\"Below code is used to get values from 2D array\"\"\"\n",
    "x = input_sequences[:, :-1]  # All rows and all columns expect last one\n",
    "y = input_sequences[:, -1]   # All rows and last column\n",
    "\n",
    "print(\"\\nInput features type: \", type(x))\n",
    "print(\"Label type: \", type(y))\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326825ae-85f2-4e38-838e-e18d94ababe6",
   "metadata": {},
   "source": [
    "#### Step 4: Building the LSTM Text Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376dd461-4d33-4441-8d3d-ec4d3a992c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 21:31:09.690218: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 26383, 100)        275300    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2753)              415703    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 841,603\n",
      "Trainable params: 841,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 21:31:09.941746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-05-31 21:31:09.943462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-05-31 21:31:09.944410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=x.shape[1]))\n",
    "model.add(LSTM(units=150, return_sequences=False))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded279c-22e3-453a-bf2b-6d92a0e20270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 21:31:12.119533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-05-31 21:31:12.120947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-05-31 21:31:12.122247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-05-31 21:31:12.717357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-05-31 21:31:12.718762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-05-31 21:31:12.719907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/413 [..............................] - ETA: 19:42:06 - loss: 7.8915 - accuracy: 0.0260    "
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=30, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ec426-0007-4698-ab7a-87e6d397fde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
